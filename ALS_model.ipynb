{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALS-model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5vMfHBKprYsL/+N5ZC/1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ale1995co/Final-Capstone/blob/master/ALS_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M-ML5yEVphs",
        "colab_type": "code",
        "outputId": "90302843-91e8-4009-e964-a029d7ab5684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# Install Java, Spark, Findspark and PySpark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 59kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=860cc2e90b90af1144f360e2eab29fd8e4bd9c20051d38ea9118a34bb82584f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y10EG4DWVkcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# spark imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
        "from pyspark.sql.types import StringType, ArrayType\n",
        "from pyspark.mllib.recommendation import ALS\n",
        "from pyspark.sql import Row,SQLContext, SparkSession\n",
        "\n",
        "# data science imports\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualization imports\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkFSMgMuV85F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USERS_PATH = \"/content/gdrive/My Drive/Colab Notebooks/Colab Datasets/Final Capstone/users_cleaned.csv\" \n",
        "ANIME_PATH = \"/content/gdrive/My Drive/Colab Notebooks/Colab Datasets/Final Capstone/anime_cleaned.csv\"\n",
        "SCORES_PATH = \"/content/gdrive/My Drive/Colab Notebooks/Colab Datasets/Final Capstone/animelists_cleaned.csv\"\n",
        "APP_NAME = \"Anime Recommender\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-TqfvyjxZ6L",
        "colab_type": "text"
      },
      "source": [
        "# Context \n",
        "\n",
        "The csvs that are use for pyspark are the clean ones. The creator of the dataset omitted rows that has rows the best of his ability. I tried running the filtered ones but it was giving me errors through pyspark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pINFdQ-XXHk",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtxKvphrWCqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sqlContext = SQLContext(sc)\n",
        "usersdf = spark.read.load(os.path.join(USERS_PATH), format='csv', header=True, inferSchema=True)\n",
        "animedf = spark.read.load(os.path.join(ANIME_PATH), format='csv', header=True, inferSchema=True)\n",
        "scoresdf =spark.read.load(os.path.join(SCORES_PATH), format='csv', header=True, inferSchema=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mFYeUt5YXjV",
        "colab_type": "code",
        "outputId": "05a11d25-9225-48bc-e8f2-4f1361afbe2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "usersdf.show(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------+-------------+--------------+-----------+------------+----------------+------------------------+------+-------------------+-------------------+-----------+-------------------+-------------------+----------------+---------------+--------------+\n",
            "|      username|user_id|user_watching|user_completed|user_onhold|user_dropped|user_plantowatch|user_days_spent_watching|gender|           location|         birth_date|access_rank|          join_date|        last_online|stats_mean_score|stats_rewatched|stats_episodes|\n",
            "+--------------+-------+-------------+--------------+-----------+------------+----------------+------------------------+------+-------------------+-------------------+-----------+-------------------+-------------------+----------------+---------------+--------------+\n",
            "|      karthiga|2255153|            3|            49|          1|           0|               0|       55.09166666666667|Female|    Chennai, India |1990-04-29 00:00:00|       null|2013-03-03 00:00:00|2014-02-04 01:32:00|            7.43|            0.0|        3391.0|\n",
            "|     Damonashu|  37326|           45|           195|         27|          25|              59|       82.57430555555555|  Male|   Detroit,Michigan|1991-08-01 00:00:00|       null|2008-02-13 00:00:00|2017-07-10 06:52:54|            6.15|            6.0|        4903.0|\n",
            "|         bskai| 228342|           25|           414|          2|           5|              11|      159.48333333333332|  Male|    Nayarit, Mexico|1990-12-14 00:00:00|       null|2009-08-31 00:00:00|2014-05-12 16:35:00|            8.27|            1.0|        9701.0|\n",
            "|terune_uzumaki| 327311|            5|             5|          0|           0|               0|      11.394444444444444|Female|  Malaysia, Kuantan|1998-08-24 00:00:00|       null|2010-05-10 00:00:00|2012-10-18 19:06:00|             9.7|            6.0|         697.0|\n",
            "|         Bas_G|5015094|           35|           114|          6|          20|             175|      30.458333333333332|  Male|Nijmegen, Nederland|1999-10-24 00:00:00|       null|2015-11-26 00:00:00|2018-05-10 20:53:37|            7.86|            0.0|        1847.0|\n",
            "+--------------+-------+-------------+--------------+-----------+------------+----------------+------------------------+------+-------------------+-------------------+-----------+-------------------+-------------------+----------------+---------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn36mANiY-8f",
        "colab_type": "code",
        "outputId": "9e0d4144-b417-4dde-ade9-eb83fc80ffa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "animedf.show(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------------------+--------------------+----------------------+--------------------+--------------------+----+--------+--------+---------------+------+--------------------+--------------------+---------------+--------------------+-----+---------+------+----------+--------+---------+--------------------+-----------+------------------+--------------------+--------------------+----------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|anime_id|              title|       title_english|        title_japanese|      title_synonyms|           image_url|type|  source|episodes|         status|airing|        aired_string|               aired|       duration|              rating|score|scored_by|  rank|popularity| members|favorites|          background|  premiered|         broadcast|             related|            producer|        licensor|          studio|               genre|       opening_theme|        ending_theme|        duration_min|     aired_from_year|\n",
            "+--------+-------------------+--------------------+----------------------+--------------------+--------------------+----+--------+--------+---------------+------+--------------------+--------------------+---------------+--------------------+-----+---------+------+----------+--------+---------+--------------------+-----------+------------------+--------------------+--------------------+----------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   11013|      Inu x Boku SS|Inu X Boku Secret...|             妖狐×僕SS|     Youko x Boku SS|https://myanimeli...|  TV|   Manga|      12|Finished Airing| False|Jan 13, 2012 to M...|{'from': '2012-01...|24 min. per ep.|PG-13 - Teens 13 ...| 7.63|   139250|1274.0|     231.0|283882.0|     2809|Inu x Boku SS was...|Winter 2012|Fridays at Unknown|{'Adaptation': [{...|Aniplex, Square E...|Sentai Filmworks|David Production|Comedy, Supernatu...|\"['\"\"Nirvana\"\" by...|\"['#1: \"\"Nirvana\"...|             11-12)'| '#2: \"\"Rakuen no...|\n",
            "|    2104|   Seto no Hanayome|My Bride is a Mer...|            瀬戸の花嫁|The Inland Sea Bride|https://myanimeli...|  TV|   Manga|      26|Finished Airing| False|Apr 2, 2007 to Oc...|{'from': '2007-04...|24 min. per ep.|PG-13 - Teens 13 ...| 7.89|    91206| 727.0|     366.0|204003.0|     2579|                null|Spring 2007|           Unknown|{'Adaptation': [{...|TV Tokyo, AIC, Sq...|      Funimation|           Gonzo|Comedy, Parody, R...|\"['\"\"Romantic sum...|\"['#1: \"\"Ashita e...|                26)'| '#2: \"\"Dan Dan D...|\n",
            "|    5262| Shugo Chara!! Doki|  Shugo Chara!! Doki|しゅごキャラ！！どきっ|Shugo Chara Ninen...|https://myanimeli...|  TV|   Manga|      51|Finished Airing| False|Oct 4, 2008 to Se...|{'from': '2008-10...|24 min. per ep.|       PG - Children| 7.55|    37129|1508.0|    1173.0| 70127.0|      802|                null|  Fall 2008|           Unknown|{'Adaptation': [{...|     TV Tokyo, Sotsu|            null|       Satelight|Comedy, Magic, Sc...|\"['#1: \"\"Minna no...| '#2: \"\"Shugo Shu...| '#3: \"\"Omakase♪G...| '#4: \"\"School Da...|\n",
            "|     721|      Princess Tutu|       Princess Tutu|    プリンセスチュチュ|                null|https://myanimeli...|  TV|Original|      38|Finished Airing| False|Aug 16, 2002 to M...|{'from': '2002-08...|16 min. per ep.|PG-13 - Teens 13 ...| 8.21|    36501| 307.0|     916.0| 93312.0|     3344|Princess Tutu air...|Summer 2002|Fridays at Unknown|{'Adaptation': [{...|Memory-Tech, GANS...|       ADV Films|  Hal Film Maker|Comedy, Drama, Ma...|\"['\"\"Morning Grac...|\"['\"\"Watashi No A...|                16.0|              2002.0|\n",
            "|   12365|Bakuman. 3rd Season|            Bakuman.|            バクマン。|    Bakuman Season 3|https://myanimeli...|  TV|   Manga|      25|Finished Airing| False|Oct 6, 2012 to Ma...|{'from': '2012-10...|24 min. per ep.|PG-13 - Teens 13 ...| 8.67|   107767|  50.0|     426.0|182765.0|     2082|                null|  Fall 2012|           Unknown|{'Adaptation': [{...|       NHK, Shueisha|            null|       J.C.Staff|Comedy, Drama, Ro...|\"['#1: \"\"Moshimo ...| '#2: \"\"23:40 (23...|\"['#1: \"\"Pride on...| '#2: \"\"Yume Sket...|\n",
            "+--------+-------------------+--------------------+----------------------+--------------------+--------------------+----+--------+--------+---------------+------+--------------------+--------------------+---------------+--------------------+-----+---------+------+----------+--------+---------+--------------------+-----------+------------------+--------------------+--------------------+----------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCGJqSBbYYIx",
        "colab_type": "code",
        "outputId": "32d4889e-9a87-4d53-98ac-99e57a35c857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "scoresdf.show(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------+-------------------+-------------+--------------+--------+---------+-------------+----------------+-------------------+-------+\n",
            "|username|anime_id|my_watched_episodes|my_start_date|my_finish_date|my_score|my_status|my_rewatching|my_rewatching_ep|    my_last_updated|my_tags|\n",
            "+--------+--------+-------------------+-------------+--------------+--------+---------+-------------+----------------+-------------------+-------+\n",
            "|karthiga|      21|                586|   0000-00-00|    0000-00-00|       9|        1|         null|               0|2013-03-03 10:52:53|   null|\n",
            "|karthiga|      59|                 26|   0000-00-00|    0000-00-00|       7|        2|         null|               0|2013-03-10 13:54:51|   null|\n",
            "|karthiga|      74|                 26|   0000-00-00|    0000-00-00|       7|        2|         null|               0|2013-04-27 16:43:35|   null|\n",
            "|karthiga|     120|                 26|   0000-00-00|    0000-00-00|       7|        2|         null|               0|2013-03-03 10:53:57|   null|\n",
            "|karthiga|     178|                 26|   0000-00-00|    0000-00-00|       7|        2|          0.0|               0|2013-03-27 15:59:13|   null|\n",
            "+--------+--------+-------------------+-------------+--------------+--------+---------+-------------+----------------+-------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozzNlN_eZD1x",
        "colab_type": "code",
        "outputId": "cf320717-1a3d-493e-e204-436ebf096174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "scoresdf.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('username', 'string'),\n",
              " ('anime_id', 'string'),\n",
              " ('my_watched_episodes', 'string'),\n",
              " ('my_start_date', 'string'),\n",
              " ('my_finish_date', 'string'),\n",
              " ('my_score', 'string'),\n",
              " ('my_status', 'string'),\n",
              " ('my_rewatching', 'string'),\n",
              " ('my_rewatching_ep', 'string'),\n",
              " ('my_last_updated', 'string'),\n",
              " ('my_tags', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBAM4K3OZK7Z",
        "colab_type": "code",
        "outputId": "e3a2e31a-ad40-42a2-b8cf-cc35900a0ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "scoresdf = scoresdf.drop(\"my_watched_episodes\", \"my_start_date\", \"my_finish_date\", \"my_rewatching\", \n",
        "                         \"my_last_updated\", \"my_tags\", \"my_status\", \"my_rewatching_ep\" )\n",
        "scoresdf.show(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------+--------+\n",
            "|username|anime_id|my_score|\n",
            "+--------+--------+--------+\n",
            "|karthiga|      21|       9|\n",
            "|karthiga|      59|       7|\n",
            "|karthiga|      74|       7|\n",
            "|karthiga|     120|       7|\n",
            "|karthiga|     178|       7|\n",
            "+--------+--------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpBuQ3b4v3bn",
        "colab_type": "text"
      },
      "source": [
        "The ALS model only use three features. Breaking this dataframe to down organize it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "532MnptPwOax",
        "colab_type": "text"
      },
      "source": [
        "## Questions I like to answer using pyspark tools:\n",
        "\n",
        "What are the scores?\n",
        "What is the total number of users in the data sets?\n",
        "What is the total number of anime in the data sets?\n",
        "How many anime are rated by users? List how many anime not rated yet?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmzhrLYzZNWB",
        "colab_type": "code",
        "outputId": "c1e2f98c-99d8-4c79-e0ea-32c16197f68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scoresdf.dtypes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('username', 'string'), ('anime_id', 'string'), ('my_score', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB_j4jTIZWey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import IntegerType"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOE5iqQ6ZQgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scoresdf = scoresdf.withColumn(\"my_score\", scoresdf[\"my_score\"].cast(IntegerType()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvQPGW0SwVM6",
        "colab_type": "text"
      },
      "source": [
        "Changing the my_score to integers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbZVyjFowbfQ",
        "colab_type": "text"
      },
      "source": [
        "What are the scores?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H72jDsqwZTJJ",
        "colab_type": "code",
        "outputId": "357ee6f6-02a3-4ee3-d6b1-d94a177a8a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "scoresdf.groupby(\"my_score\")\\\n",
        "        .count()\\\n",
        "        .show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------+\n",
            "|my_score|   count|\n",
            "+--------+--------+\n",
            "|    null|  100962|\n",
            "|       1|  103177|\n",
            "|       6| 2128502|\n",
            "|       3|  223202|\n",
            "|       5| 1085660|\n",
            "|       9| 3443674|\n",
            "|      17|       1|\n",
            "|       4|  480871|\n",
            "|       8| 4834595|\n",
            "|       7| 4234726|\n",
            "|      10| 2507404|\n",
            "|       2|  130314|\n",
            "|    2017|       1|\n",
            "|       0|12111905|\n",
            "+--------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzyjgUq2ZacS",
        "colab_type": "code",
        "outputId": "0a5a843d-b9e3-4bd6-c2fe-618db2b9f1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# null, 17, 0, 2017 doesn't exist in the rating system. \n",
        "scoresdf = scoresdf.na.drop()\n",
        "scoresdf = scoresdf.filter((scoresdf[\"my_score\"] != 0) & (scoresdf[\"my_score\"] != 2017) & (scoresdf[\"my_score\"] != 17 ))\n",
        "scoresdf.groupby(\"my_score\")\\\n",
        "        .count()\\\n",
        "        .show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------+\n",
            "|my_score|  count|\n",
            "+--------+-------+\n",
            "|       1| 103177|\n",
            "|       6|2128502|\n",
            "|       3| 223202|\n",
            "|       5|1085660|\n",
            "|       9|3443674|\n",
            "|       4| 480871|\n",
            "|       8|4834595|\n",
            "|       7|4234726|\n",
            "|      10|2507404|\n",
            "|       2| 130314|\n",
            "+--------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsE1QaZ2wiss",
        "colab_type": "text"
      },
      "source": [
        "What is the total number of users in the data sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyov-I1IwnD7",
        "colab_type": "code",
        "outputId": "f897ca36-81e9-41a8-b20f-96b0a7cb9b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp = scoresdf.select('username').distinct().count()\n",
        "print('We have a total of {} distinct users in the data sets'.format(tmp))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have a total of 106402 distinct users in the data sets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qvi3Xc4wpBb",
        "colab_type": "text"
      },
      "source": [
        "How many anime are rated by users? List how many anime not rated yet?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kb_cvNqwuHY",
        "colab_type": "code",
        "outputId": "192502b0-d13c-43db-e156-e98103ff37e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tmp1 = animedf.select('anime_id').distinct().count()\n",
        "tmp2 = scoresdf.select('anime_id').distinct().count()\n",
        "print('We have a total of {} distinct anime that are rated by users in ratings table'.format(tmp2))\n",
        "print('We have {} anime that are not rated yet'.format(tmp1-tmp2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have a total of 6598 distinct anime that are rated by users in ratings table\n",
            "We have 70 anime that are not rated yet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mI5TQdYwzgb",
        "colab_type": "code",
        "outputId": "f3cbe38c-8471-43d2-c2b6-01d2ee94ab78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "animedf.createOrReplaceTempView(\"animedf\")\n",
        "scoresdf.createOrReplaceTempView(\"scoresdf\")\n",
        "print('List movies that are not rated yet: ')\n",
        "# SQL query (NOTE: WHERE ... NOT IN ... == ... LEFT JOIN ... WHERE ... IS NULL)\n",
        "# Approach 1\n",
        "spark.sql(\n",
        "    \"SELECT anime_id, title \"\n",
        "    \"FROM animedf \"\n",
        "    \"WHERE anime_id NOT IN (SELECT distinct(anime_id) FROM scoresdf)\"\n",
        ").show(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List movies that are not rated yet: \n",
            "+--------+--------------------+\n",
            "|anime_id|               title|\n",
            "+--------+--------------------+\n",
            "|    7639|Shounen Santa no ...|\n",
            "|   33310|Peach Command Shi...|\n",
            "|   28119|Kuma no Minakuro ...|\n",
            "|   33484|          Shiroi Zou|\n",
            "|   31020|Norasco: Cinema P...|\n",
            "|   34091|    Norasco Specials|\n",
            "|   32663|Tama & Friends: U...|\n",
            "|   37187| Kuiba Yao Xia Zhuan|\n",
            "|   20001|     Mouretsu Atarou|\n",
            "|   23537|  Two Down Full Base|\n",
            "+--------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPjS65RCyDan",
        "colab_type": "text"
      },
      "source": [
        "Converting the two dataframes of user-id, anime_id, scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA6OZe5bZuWa",
        "colab_type": "code",
        "outputId": "d47971a5-896f-4386-921c-0eb1abac215d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "left_join = usersdf.join(scoresdf, usersdf.username == scoresdf.username,how='left') # Could also use 'left_outer'\n",
        "left_join.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------+-------------+--------------+-----------+------------+----------------+------------------------+------+--------------------+-------------------+-----------+-------------------+-------------------+----------------+---------------+--------------+--------+--------+--------+\n",
            "|username|user_id|user_watching|user_completed|user_onhold|user_dropped|user_plantowatch|user_days_spent_watching|gender|            location|         birth_date|access_rank|          join_date|        last_online|stats_mean_score|stats_rewatched|stats_episodes|username|anime_id|my_score|\n",
            "+--------+-------+-------------+--------------+-----------+------------+----------------+------------------------+------+--------------------+-------------------+-----------+-------------------+-------------------+----------------+---------------+--------------+--------+--------+--------+\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     178|       8|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     853|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    1698|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    3092|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    3731|      10|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    4224|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    4814|      10|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    6045|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    7054|       8|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    7674|      10|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    7817|       8|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|    9656|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|      68|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     226|       8|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     243|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     245|       8|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     326|       9|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     442|       8|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     746|      10|\n",
            "| -Himeko|2156961|           13|           164|          0|           0|               0|       34.59513888888889|Female|Buenos Aires - Ar...|1996-09-04 00:00:00|       null|2013-02-09 00:00:00|2017-04-03 22:11:00|            8.66|            0.0|        2132.0| -Himeko|     850|       8|\n",
            "+--------+-------+-------------+--------------+-----------+------------+----------------+------------------------+------+--------------------+-------------------+-----------+-------------------+-------------------+----------------+---------------+--------------+--------+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiFQ1lihaJcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_join= left_join.select(\"user_id\", \"my_score\", \"anime_id\" )\n",
        "#Only need three features for the ALS model. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQMNo1L0a4la",
        "colab_type": "code",
        "outputId": "ca8368aa-4917-4bda-bef5-d7362870b9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "left_join.printSchema()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- my_score: integer (nullable = true)\n",
            " |-- anime_id: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubWFzfFRy1vp",
        "colab_type": "text"
      },
      "source": [
        "# ALS Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txm1YhAZza0-",
        "colab_type": "text"
      },
      "source": [
        "ALS is one of the low rank matrix approximation algorithms for collaborative filtering. ALS decomposes user-item matrix into two low rank matrixes: user matrix and item matrix. In collaborative filtering, users and products are described by a small set of latent factors that can be used to predict missing entries. And ALS algorithm learns these latent factors by matrix factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-TzkNT-bDNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_join = left_join.withColumn(\"anime_id\", scoresdf[\"anime_id\"].cast(IntegerType()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NXfFOpDbR5C",
        "colab_type": "code",
        "outputId": "a0746068-5858-4723-9887-81ed49a941c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "left_join.printSchema"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.printSchema of DataFrame[user_id: int, my_score: int, anime_id: int]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMLcC77xbT5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split dataset to train and test\n",
        "train_data, test_data = left_join.randomSplit([0.8, 0.2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSRxRTi4brGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLCQyhsdchRH",
        "colab_type": "code",
        "outputId": "20dac788-36f1-4501-fe90-6929158f6a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "left_join = left_join.na.drop()\n",
        "#nulls will crash the ALS model\n",
        "left_join.describe()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, user_id: string, my_score: string, anime_id: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ZwgLrWbfXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ALS(userCol='user_id', itemCol='anime_id', ratingCol='my_score').fit(left_join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnhnlMrpbhAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4SZM6fVgxCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainingRatings, testRatings) = left_join.randomSplit([80.0, 20.0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk6gsYOEfEF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "als = ALS(userCol='user_id', itemCol='anime_id', ratingCol='my_score')\n",
        "model = als.fit(trainingRatings)\n",
        "predictions = model.transform(testRatings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94x1W5OrikwK",
        "colab_type": "code",
        "outputId": "8dc5d645-5ee7-4b7a-95ec-8f2a26756568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "predictions.toPandas().head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>my_score</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>252259</td>\n",
              "      <td>7</td>\n",
              "      <td>148</td>\n",
              "      <td>4.653338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>285987</td>\n",
              "      <td>7</td>\n",
              "      <td>148</td>\n",
              "      <td>6.841636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26111</td>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>5.921710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91084</td>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>6.213613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58066</td>\n",
              "      <td>8</td>\n",
              "      <td>148</td>\n",
              "      <td>6.544576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  my_score  anime_id  prediction\n",
              "0   252259         7       148    4.653338\n",
              "1   285987         7       148    6.841636\n",
              "2    26111         6       148    5.921710\n",
              "3    91084         6       148    6.213613\n",
              "4    58066         8       148    6.544576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iPvP8pcjdnZ",
        "colab_type": "code",
        "outputId": "f0a6d8df-78a5-41f1-973d-f0a971f59c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='my_score', predictionCol='prediction')\n",
        "print('The root mean squared error for our model is: {}'.format(evaluator.evaluate(predictions)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The root mean squared error for our model is: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfXNqz9B06_V",
        "colab_type": "text"
      },
      "source": [
        "nan happens when the model can't predict value that they don't have data on.\n",
        "\n",
        "Replace predicted NaN values with the average rating and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8penv1ykThI",
        "colab_type": "code",
        "outputId": "c557b2ac-38b8-45a6-83ac-c66a521466f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "avgRatings = left_join.select('my_score').groupBy().avg().first()[0]\n",
        "print ('The average rating in the dataset is: {}'.format(avgRatings))\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='my_score', predictionCol='prediction')\n",
        "print ('The root mean squared error for our model is: {}'.format(evaluator.evaluate(predictions.na.fill(avgRatings))))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average rating in the dataset is: 7.59139401605195\n",
            "The root mean squared error for our model is: 1.2301980583899745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49HnPj1P1X6k",
        "colab_type": "text"
      },
      "source": [
        "Now exclude predicted NaN values and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m8nUpJ2kj_B",
        "colab_type": "code",
        "outputId": "43d1df10-26e4-4f3a-c90a-48e28db23c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='my_score', predictionCol='prediction')\n",
        "print ('The root mean squared error for our model is: {}'.format(evaluator.evaluate(predictions.na.drop())))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The root mean squared error for our model is: 1.2300982176995245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilIt_NQt1_Uc",
        "colab_type": "text"
      },
      "source": [
        "Now we can run the model to test the recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSJj5oLmmqXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import lit\n",
        "\n",
        "def recommendMovies(model, user, nbRecommendations):\n",
        "    # Create a Spark DataFrame with the specified user and all the anime listed in the ratings DataFrame\n",
        "    dataSet = left_join.select('anime_id').distinct().withColumn('user_id', lit(user))\n",
        "\n",
        "    # Create a Spark DataFrame with the anime that have already been rated by this user\n",
        "    moviesAlreadyRated = left_join.filter(left_join.user_id == user).select('anime_id', 'user_id')\n",
        "\n",
        "    # Apply the recommender system to the data set without the already rated anime to predict ratings\n",
        "    predictions = model.transform(dataSet.subtract(moviesAlreadyRated)).dropna().orderBy('prediction', ascending=False).limit(nbRecommendations).select('anime_id', 'prediction')\n",
        "\n",
        "    # Join with the movies DataFrame to get the anime titles and genres\n",
        "    recommendations = predictions.join(animedf, predictions.anime_id == animedf.anime_id).select(predictions.anime_id, animedf.title, animedf.genre, predictions.prediction, animedf.premiered)\n",
        "\n",
        "#     recommendations.show(truncate=False)\n",
        "    return recommendations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVxNfxI0mw1O",
        "colab_type": "code",
        "outputId": "cc66122c-5b47-4c39-d800-e3ec17eaf13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "print('Recommendations for user 3924291:')\n",
        "recommendMovies(model, 3924291, 10).toPandas()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recommendations for user 3924291:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anime_id</th>\n",
              "      <th>title</th>\n",
              "      <th>genre</th>\n",
              "      <th>prediction</th>\n",
              "      <th>premiered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35478</td>\n",
              "      <td>Neko no Robu</td>\n",
              "      <td>Comedy, Slice of Life</td>\n",
              "      <td>9.476129</td>\n",
              "      <td>Spring 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32281</td>\n",
              "      <td>Kimi no Na wa.</td>\n",
              "      <td>Supernatural, Drama, Romance, School</td>\n",
              "      <td>9.002776</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28977</td>\n",
              "      <td>Gintama°</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>9.162655</td>\n",
              "      <td>Spring 2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15417</td>\n",
              "      <td>Gintama&amp;#039;: Enchousen</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>8.993153</td>\n",
              "      <td>Fall 2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30484</td>\n",
              "      <td>Steins;Gate 0</td>\n",
              "      <td>Sci-Fi, Thriller</td>\n",
              "      <td>9.004238</td>\n",
              "      <td>Spring 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>28851</td>\n",
              "      <td>Koe no Katachi</td>\n",
              "      <td>Drama, School, Shounen</td>\n",
              "      <td>8.849479</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9969</td>\n",
              "      <td>Gintama&amp;#039;</td>\n",
              "      <td>Action, Sci-Fi, Comedy, Historical, Parody, Sa...</td>\n",
              "      <td>9.060499</td>\n",
              "      <td>Spring 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>34096</td>\n",
              "      <td>Gintama.</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>8.962780</td>\n",
              "      <td>Winter 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>263</td>\n",
              "      <td>Hajime no Ippo</td>\n",
              "      <td>Comedy, Sports, Drama, Shounen</td>\n",
              "      <td>8.846721</td>\n",
              "      <td>Fall 2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15335</td>\n",
              "      <td>Gintama Movie 2: Kanketsu-hen - Yorozuya yo Ei...</td>\n",
              "      <td>Action, Sci-Fi, Comedy, Historical, Parody, Sa...</td>\n",
              "      <td>8.966371</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   anime_id  ...    premiered\n",
              "0     35478  ...  Spring 2017\n",
              "1     32281  ...         None\n",
              "2     28977  ...  Spring 2015\n",
              "3     15417  ...    Fall 2012\n",
              "4     30484  ...  Spring 2018\n",
              "5     28851  ...         None\n",
              "6      9969  ...  Spring 2011\n",
              "7     34096  ...  Winter 2017\n",
              "8       263  ...    Fall 2000\n",
              "9     15335  ...         None\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mopu9kAapc1P",
        "colab_type": "code",
        "outputId": "5f39f94f-f7e8-4281-e718-a5d81f01cd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "print('Recommendations for user 303577:')\n",
        "recommendMovies(model, 303577, 10).toPandas()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recommendations for user 303577:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anime_id</th>\n",
              "      <th>title</th>\n",
              "      <th>genre</th>\n",
              "      <th>prediction</th>\n",
              "      <th>premiered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35478</td>\n",
              "      <td>Neko no Robu</td>\n",
              "      <td>Comedy, Slice of Life</td>\n",
              "      <td>10.540213</td>\n",
              "      <td>Spring 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28977</td>\n",
              "      <td>Gintama°</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>9.528095</td>\n",
              "      <td>Spring 2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3784</td>\n",
              "      <td>Evangelion: 2.0 You Can (Not) Advance</td>\n",
              "      <td>Action, Sci-Fi, Mecha</td>\n",
              "      <td>9.567251</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5114</td>\n",
              "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
              "      <td>Action, Military, Adventure, Comedy, Drama, Ma...</td>\n",
              "      <td>9.647413</td>\n",
              "      <td>Spring 2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36732</td>\n",
              "      <td>Qin Shi Ming Yue: Tian Xing Jiu Ge</td>\n",
              "      <td>Action, Historical, Martial Arts, Fantasy</td>\n",
              "      <td>9.684301</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9253</td>\n",
              "      <td>Steins;Gate</td>\n",
              "      <td>Thriller, Sci-Fi</td>\n",
              "      <td>9.560666</td>\n",
              "      <td>Spring 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>33473</td>\n",
              "      <td>Tokyo Futago Athletic</td>\n",
              "      <td>Comedy, Sports</td>\n",
              "      <td>10.158769</td>\n",
              "      <td>Winter 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>15417</td>\n",
              "      <td>Gintama&amp;#039;: Enchousen</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>9.536556</td>\n",
              "      <td>Fall 2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35385</td>\n",
              "      <td>Yukai na Animal Bus 2nd Season</td>\n",
              "      <td>Comedy, Kids</td>\n",
              "      <td>10.179564</td>\n",
              "      <td>Summer 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9969</td>\n",
              "      <td>Gintama&amp;#039;</td>\n",
              "      <td>Action, Sci-Fi, Comedy, Historical, Parody, Sa...</td>\n",
              "      <td>9.654662</td>\n",
              "      <td>Spring 2011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   anime_id                                  title  ... prediction    premiered\n",
              "0     35478                           Neko no Robu  ...  10.540213  Spring 2017\n",
              "1     28977                               Gintama°  ...   9.528095  Spring 2015\n",
              "2      3784  Evangelion: 2.0 You Can (Not) Advance  ...   9.567251         None\n",
              "3      5114       Fullmetal Alchemist: Brotherhood  ...   9.647413  Spring 2009\n",
              "4     36732     Qin Shi Ming Yue: Tian Xing Jiu Ge  ...   9.684301         None\n",
              "5      9253                            Steins;Gate  ...   9.560666  Spring 2011\n",
              "6     33473                  Tokyo Futago Athletic  ...  10.158769  Winter 2017\n",
              "7     15417               Gintama&#039;: Enchousen  ...   9.536556    Fall 2012\n",
              "8     35385         Yukai na Animal Bus 2nd Season  ...  10.179564  Summer 2017\n",
              "9      9969                          Gintama&#039;  ...   9.654662  Spring 2011\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDQx3eJEtajj",
        "colab_type": "text"
      },
      "source": [
        "The ALS algorthim shows the top ten anime recommendation. When comparing the results from the baseline, the anime varied but both has the same anime with each other. The ALS leans toward anime that are not known but includes popular anime also. While baseline shows mostly popular anime. The RMSE for ALS is 1.22568. While Baselineonly is 1.289960.  \n",
        "\n",
        "# Conclusion\n",
        "\n",
        "If I have to use one recommendation system it would be the ALS because it accounts for all data and not samples like the baseline. Also it has a lower RSME than baseline This recomendation system would be great for the website to help recommend the users what anime to watch. Since the system cater towards people who are familar with anime. I can see it run similar like netflix or spotify recommendation system . To go further is to use all the data for the model for baseline model and knn to use it for the full potential.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldo14TCysN7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}